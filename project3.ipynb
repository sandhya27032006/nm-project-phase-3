{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "project3.ipynb",
      "authorship_tag": "ABX9TyMVWnGOqexOY6REnx/K/yJn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandhya27032006/nm-project-phase-3/blob/main/project3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "DLZkZ4Y3gRqw",
        "outputId": "e7413342-b4c4-46e5-feb6-841eef68adca"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unmatched ']' (<ipython-input-1-336d4c654f3a>, line 178)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-336d4c654f3a>\"\u001b[0;36m, line \u001b[0;32m178\u001b[0m\n\u001b[0;31m    r2 = r2_sc]\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ']'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import warnings\n",
        "\n",
        "# Step 2: Loading the Dataset\n",
        "# ------------------------------\n",
        "file_path = 'synthetic_house_prices.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first five rows\n",
        "print(data.head())\n",
        "\n",
        "# Summary statistics\n",
        "print(data.describe())\n",
        "\n",
        "# Check for missing values\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Info of the dataset\n",
        "print(data.info())\n",
        "\n",
        "# Check for non-numeric columns\n",
        "non_numeric_columns = data.select_dtypes(exclude=[np.number]).columns\n",
        "print(f\"Non-numeric columns: {non_numeric_columns}\")\n",
        "\n",
        "# If there are non-numeric columns, drop them for correlation\n",
        "if len(non_numeric_columns) > 0:\n",
        "    data_numeric = data.drop(columns=non_numeric_columns)\n",
        "else:\n",
        "    data_numeric = data\n",
        "\n",
        "# Generate the correlation matrix\n",
        "corr_matrix = data_numeric.corr()\n",
        "\n",
        "# Check for NaN values\n",
        "print(f\"NaN values in correlation matrix: {corr_matrix.isnull().sum().sum()}\")\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()\n",
        "\n",
        "# Pair Plot for Numerical Features\n",
        "sns.pairplot(data[['LotArea', 'GrLivArea', 'OverallQual', 'SalePrice']])\n",
        "plt.show()\n",
        "\n",
        "# Distribution of SalePrice\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(data['SalePrice'], kde=True, color='green')\n",
        "plt.title('Distribution of Sale Price')\n",
        "plt.show()\n",
        "\n",
        "# Bar Plot for Neighborhood\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.barplot(x=data['Neighborhood'].value_counts().index, y=data['Neighborhood'].value_counts().values, palette='viridis')\n",
        "plt.title('Number of Houses by Neighborhood')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\"\"\n",
        "\n",
        "# ------------------------------\n",
        "# Step 4: Data Preprocessing\n",
        "# ------------------------------\n",
        "\n",
        "# 1. Encoding categorical features\n",
        "data = pd.get_dummies(data, columns=['Neighborhood'], drop_first=True)\n",
        "\n",
        "# 2. Splitting features and target variable\n",
        "X = data.drop('SalePrice', axis=1)\n",
        "y = data['SalePrice']\n",
        "\n",
        "# 3. Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Display shapes of training and testing data\n",
        "print(f\"Training data shape: {X_train.shape}\")\n",
        "print(f\"Testing data shape: {X_test.shape}\")\n",
        "\n",
        "# Ddefine models to train\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Ridge Regression': Ridge(),\n",
        "    'Lasso Regression': Lasso(),\n",
        "    'Random Forest': RandomForestRegressor(),\n",
        "    'Gradient Boosting': GradientBoostingRegressor()\n",
        "}\n",
        "\n",
        "# Train and evaluate each model\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"{name} - MAE: {mae:.2f}, MSE: {mse:.2f}, RMSE: {rmse:.2f}, R2: {r2:.2f}\")\n",
        "\n",
        "# Example: Hyperparameter tuning for Random Forest\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(RandomForestRegressor(), param_grid, cv=3, scoring='neg_mean_squared_error')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters for Random Forest: {grid_search.best_params_}\")\n",
        "print(f\"Best cross-validation score: {grid_search.best_score_:.2f}\")\n",
        "\n",
        "# Ensure grid_search is fitted before accessing the best estimator\n",
        "if grid_search.best_estimator_ is not None:\n",
        "    best_rf = grid_search.best_estimator_\n",
        "else:\n",
        "    print(\"Error: GridSearchCV wasn't fitted successfully.\")\n",
        "\n",
        "# Train the best model (using Random Forest in this case) on the entire dataset\n",
        "best_rf.fit(X_train, y_train)\n",
        "\n",
        "# Make final predictions on the test data\n",
        "final_predictions = best_rf.predict(X_test)\n",
        "\n",
        "# Evaluate final model performance\n",
        "final_mae = mean_absolute_error(y_test, final_predictions)\n",
        "final_mse = mean_squared_error(y_test, final_predictions)\n",
        "final_rmse = np.sqrt(final_mse)\n",
        "final_r2 = r2_score(y_test, final_predictions)\n",
        "\n",
        "print(f\"Final Model - MAE: {final_mae:.2f}, MSE: {final_mse:.2f}, RMSE: {final_rmse:.2f}, R2: {final_r2:.2f}\")\n",
        "\n",
        "# ------------------------------\n",
        "# Step 8: Conclusion\n",
        "# ------------------------------\n",
        "# Check if final_predictions are available and valid\n",
        "if len(final_predictions) > 0:\n",
        "    final_mae = mean_absolute_error(y_test, final_predictions)\n",
        "    final_mse = mean_squared_error(y_test, final_predictions)\n",
        "    final_rmse = np.sqrt(final_mse)\n",
        "    final_r2 = r2_score(y_test, final_predictions)\n",
        "\n",
        "    # Display final performance metrics\n",
        "    print(f\"Final Model - MAE: {final_mae:.2f}, MSE: {final_mse:.2f}, RMSE: {final_rmse:.2f}, R2: {final_r2:.2f}\")\n",
        "else:\n",
        "    print(\"Error: Final predictions are empty or not available.\")\n",
        "\n",
        "# Optionally, save the final model\n",
        "import joblib\n",
        "try:\n",
        "    joblib.dump(best_rf, 'house_price_forecasting_model.pkl')\n",
        "    print(\"Model saved as 'house_price_forecasting_model.pkl'\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving model: {e}\")\n",
        "\n",
        "# ------------------------------\n",
        "# Step 9: Model Comparison & Reporting\n",
        "# ------------------------------\n",
        "\n",
        "# Store model names and their corresponding evaluation metrics\n",
        "model_comparison = []\n",
        "\n",
        "# Train and evaluate each model\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Compute performance metrics\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_sc\n",
        "        'Model': name,\n",
        "        'MAE': mae,\n",
        "        'MSE': mse,\n",
        "        'RMSE': rmse,\n",
        "        'R2': r2\n",
        "    })\n",
        "\n",
        "# Convert the list into a DataFrame for easier visualization\n",
        "comparison_df = pd.DataFrame(model_comparison)\n",
        "\n",
        "â€¦plt.title('Model Comparison (R2 Score)')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "[ ]\n",
        "# Example: Saving Model Comparison to CSV\n",
        "comparison_df.to_csv('model_comparison.csv', index=False)\n",
        "\n",
        "\n",
        "[ ]\n",
        "# Saving the best model (e.g., Random Forest)\n",
        "import joblib\n",
        "joblib.dump(best_rf, 'house_price_forecasting_model.pkl')\n",
        "\n",
        "['house_price_forecasting_model.pkl']\n",
        "Colab paid products - Cancel contracts here\n",
        "ore(y_test, y_pred)\n",
        "\n",
        "    # Store the metrics in a list\n",
        "    model_comparison.append({\n",
        "        'Model': name,\n",
        "        'MAE': mae,\n",
        "        'MSE': mse,\n",
        "        'RMSE': rmse,\n",
        "        'R2': r2\n",
        "    })\n",
        "\n",
        "# Convert the list into a DataFrame for easier visualization\n",
        "comparison_df = pd.DataFrame(model_comparison)\n",
        "\n",
        "# Sort models by R2 score for better readability\n",
        "comparison_df = comparison_df.sort_values(by='R2', ascending=False)\n",
        "\n",
        "# Display the model comparison table\n",
        "print(\"Model Comparison Report:\")\n",
        "print(comparison_df)\n",
        "\n",
        "# Optionally, visualize model performance using a bar plot for R2 score\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.barplot(x='R2', y='Model', data=comparison_df, palette='viridis')\n",
        "plt.title('Model Comparison (R2 Score)')\n",
        "plt.show()\n",
        "\n",
        "# Example: Saving Model Comparison to CSV\n",
        "comparison_df.to_csv('model_comparison.csv', index=False)\n",
        "\n",
        "# Saving the best model (e.g., Random Forest)\n",
        "import joblib\n",
        "joblib.dump(best_rf, 'house_price_forecasting_model.pkl')\n"
      ]
    }
  ]
}